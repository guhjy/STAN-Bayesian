\documentclass[a4]{beamer}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{newlfont}
\usepackage{amsmath,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{mathptmx}  % Font Family
\usepackage{helvet}   % Font Family
\usepackage{color}

\mode<presentation> {
 \usetheme{Default} % was
 \useinnertheme{rounded}
 \useoutertheme{infolines}
 \usefonttheme{serif}
 %\usecolortheme{wolverine}
% \usecolortheme{rose}
\usefonttheme{structurebold}
}

\setbeamercovered{dynamic}

\title[MA4413]{Statistics for Computing \\ {\normalsize MA4413 Lecture 6B}}
\author[Kevin O'Brien]{Kevin O'Brien \\ {\scriptsize Kevin.obrien@ul.ie}}
\date{Autumn Semester 2013}
\institute[Maths \& Stats]{Dept. of Mathematics \& Statistics, \\ University \textit{of} Limerick}

\renewcommand{\arraystretch}{1.5}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

% - Last lecture
% - symmetric Intervals
% - computing Quantiles
% - student's t distribution
% - CI for means
% - CI for means ( small samples)
% - CI for Props
% - CI for differences.


%-----------------------------------------------------------%

\begin{frame}
\frametitle{Computing Confidence Intervals}
Confidence limits are the lower and upper boundaries / values of a confidence interval, that is, the values which define the range of a confidence interval. The general structure of a confidence interval is as follows:

\[ \mbox{Point Estimate}  \pm \left[ \mbox{Quantile} \times \mbox{Standard Error} \right] \]


\begin{description}
\item[Point Estimate]: estimate for population parameter of interest, i.e. sample mean, sample proportion.
\item[Quantile]: a value from a probability distribution that scales the intervals according to the specified confidence level.
\item[Standard Error]: measures the dispersion of the sampling distribution for a given sample size $n$.
\end{description}
\end{frame}



%-----------------------------------------------------------%


\begin{frame}
\frametitle{Confidence Intervals (Revision) }

\begin{itemize}
\item The $95\%$ confidence interval is a range of values which contain the true population parameter (i.e. mean, proportion etc) with a probability of $95\%$.
\item We can expect that a $95\%$ confidence interval will not include the true parameter values $5\%$ of the time.
\item A confidence level of $95\%$ is commonly used for computing confidence interval, but we could also have confidence levels of $90\%$, $99\%$ and $99.9\%$.
\end{itemize}

\end{frame}

%-----------------------------------------------------------%


\begin{frame}
\frametitle{Confidence Level (Revision) }

\begin{itemize}
\item A confidence level for an interval is denoted to $1-\alpha$ (in percentages: $100(1-\alpha)\%$) for some value $\alpha$.
\item A confidence level of $95\%$ corresponds to $\alpha = 0.05$.
\item $100(1-\alpha)\%$ = $100(1-0.05)\%$  = $100(0.95)\%$ = $95\%$
\item For a confidence level of $99\%$, $\alpha = 0.01$.
\item Knowing the correct value for $\alpha$ is important when determining quantiles.
\end{itemize}

\end{frame}
\begin{frame}
\frametitle{Quantiles }

\begin{itemize}
\item The quantile is a value from a probability distribution that scales the intervals according to the specified confidence level.
\item For practical purposes, the quantile can be taken from the standard normal distribution, if the sample is larger than 30, further to the central limit theorem.
\item For a specified confidence level $1-\alpha $, the corresponding quantile is the value $z_o$ that satisfies the following identity (when $n > 30$):

    \[ P( -z_o \leq Z \leq z_o) = 1- \alpha \]

\end{itemize}

\end{frame}
%-----------------------------------------------------------%

\begin{frame}
\frametitle{Quantiles}

\begin{itemize} \item When the sample size $n$ is greater than 30, we can compute the quantile using Murdoch Barnes table 3.

\item $95\%$ of Z random variables are between -1.96 ( quantile for $2.5\%$)and 1.96 (quantile for $97.5\%$)
\end{itemize}

\begin{itemize}
\item If the confidence level is $95\%$, then the quantile is 1.96. Recall
\[ P( -1.96 \leq Z \leq 1.96) = 0.95 \]

\item If the confidence level is $90\%$, then the quantile is 1.645.
\[ P( -1.645 \leq Z \leq 1.645) = 0.90 \]

\item If the confidence level is $99\%$, then the quantile is 2.576.
\[ P( -2.576 \leq Z \leq 2.576) = 0.99 \]

\end{itemize}



\end{frame}
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
Broadly speaking, there are three different types of confidence interval
\begin{description}
\item[Type 1] Sample with \textbf{known} population variance
\begin{itemize}
\item The size of the sample doesn't matter.
\end{itemize}
\item[Type 2] Large sample with \textbf{unknown} population variance
\begin{itemize}
\item The size of the sample is more than 30 ($n > 30$)
\end{itemize}
\item[Type 3] Small sample with \textbf{unknown} population variance
\begin{itemize}
\item The size of the sample is 30 or less ($n\leq 30$)
\end{itemize}
\end{description}
\end{frame}

%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 1 : Known Population Variance}\\
\begin{itemize}
\item This type of confidence interval is very rare in practice, but it is very simple to implement and used as introductory
teaching material with those studying confidence intervals for the first time.
\item This type of confidence interval is computed using this formula:
\[ \bar{x} \pm z_{(\alpha/2)}{\sigma \over \sqrt{n}} \]
\item A description of each item is on the next slide.
\end{itemize}
\end{frame}


%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 1 : Known Population Variance}\\
\begin{itemize}

\item The point estimate is the sample mean : $\bar{x}$

\item We use a \textbf{\textit{quantile}} from the standard normal (Z) distribution to ``scale"
the confidence interval to the specified confidence level (usually 95\%).

\item Let the confidence level be denoted in the for $(1-\alpha)\times 100\%$, and hence determine $\alpha$.
For example, if the confidence level is 95\%, then $\alpha$ is 0.05 (or 5\%).

\item The Quantile ($z_{(\alpha/2)}$) is the value for the Standard Normal Tables (for example Murdoch Barnes Table 3) such that
\[ P(Z \geq z_{(\alpha/2)}) = {\alpha \over 2}\]

\item For a 95\% confidence interval, the quantile is 1.96. For a 99\% confidence interval, the quantile is 2.576.
\end{itemize}
\end{frame}
%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 1 : Known Population Variance}\\
\begin{itemize}

\item The population standard deviation is $\sigma$. The sample size is $n$.
\item The standard error to be used in this confidence interval is
\[ \mbox{S.E}(\bar{x}) = \frac{\sigma}{\sqrt{n}}\]

\end{itemize}
\end{frame}


%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 2 : Large Sample, Unknown Population Variance}\\
\begin{itemize}

\item The point estimate is the sample mean : $\bar{x}$

\item For a type 2 confidence interval, we can determine a \textbf{\textit{quantile}} for the confidence interval in the same way that for the Type 1 confidence interval.

\item Recall: For a 95\% confidence interval, the quantile is 1.96. For a 99\% confidence interval, the quantile is approximately 2.58.

\end{itemize}
\end{frame}

%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 2 : Large Sample, Unknown Population Variance}\\
\begin{itemize}
\item The population standard deviation which we denote $\sigma^2$ is unknown.
Instead we are given the sample variance $s^2$. We use the sample standard deviation (the square root of the variance) as an estimate for the population standard deviation $\sigma$.
\[ s \mbox{ is an estimate for } \sigma \]

\item The sample size is $n$.
\item The standard error to be used in a Type 2 confidence interval is
\[ \mbox{S.E}(\bar{x}) = \frac{s}{\sqrt{n}}\]

\end{itemize}
\end{frame}

%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 3 : Small Sample, Unknown Population Variance}\\
\begin{itemize}
\item Firstly, we will clarify the similarities of the Type 2 and Type 3 confidence interval.
\item The point estimate is the sample mean $\bar{x}$.
\item The sample standard deviation $s$ is used to estimate the population $\sigma$.
\item The standard error is
\[ \mbox{S.E}(\bar{x}) = \frac{s}{\sqrt{n}}\]
\end{itemize}
\end{frame}

%----------------------------------------------------%
%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Means}
\textbf{Type 3 : Small Sample, Unknown Population Variance}\\
\begin{itemize}
\item The key difference is in determining the quantile. Rather than use the standard normal distribution, we must use the student $t-$ distribution. Quantiles for this distribution are also tabulated in statistical tables (for Example, Murdoch Barnes Table 7).
\item Recall that we must determine a value for $\alpha$ ( and hence $\alpha/2$). For a 95\% confidence interval, $\alpha= 0.05$  and $\alpha/2 = 0.025$.
\item Computing a quantile from the $t-$ distribution additionally requires the specification of the \textit{\textbf{degrees of freedom}}. Degrees of Freedom are often denote as $df$ or by the greek letter $\nu$ (``nu").
\item For small sample confidence intervals (i.e. $n \leq 30$), the degrees of freedom are
\[ df = n-1 \]
\end{itemize}
\end{frame}




%--------------------------------------------------%
\begin{frame}
\frametitle{Using the $t-$distribution for large samples}

\begin{itemize}
\item The $t-$distribution is used for computing quantiles in the case of small samples (i.e. when sample size $n \leq 30$).
\item A key value in the $t-$distribution is the degrees of freedom, denoted $df$ (or sometimes $\nu$). For small samples \[ df= n-1\].
\item The $t-$distribution is used for computing quantiles in the case of large samples too, as an alternative to using the $Z$ distribution.
\item In this case , use the value $\infty$ as the degrees of freedom (see bottom row of table 7).
\[ df= \infty\]
\item This means that we can use the $t-$ distribution for finding the quantiles of all types of confidence intervals.

\end{itemize}
\end{frame}

%--------------------------------------------------%

%--------------------------------------------------%

%-----------------------------------------------------------%
\begin{frame}
\frametitle{The Central Limit Theorem }
\begin{itemize}
\item This theorem states that as sample size $n$ is increased, the sampling distribution of the mean (and for other sample statistics as well) approaches the normal distribution in form, regardless of the form of the population distribution from
which the sample was taken.

\item For practical purposes, the sampling distribution of the mean can be assumed to be
approximately normally distributed, even for the most non-normal populations or processes, whenever the
sample size is $n > 30$.

\item (For populations that are only somewhat non-normal, even a smaller sample size will
suffice. A variation of the normal distribution can be used for such circumstances.)
\end{itemize}


\end{frame}
%-----------------------------------------------------------%









%-----------------------------------------------------------%

\begin{frame}
\frametitle{Standard Error}

\begin{itemize}
\item The standard error measures the dispersion of the sampling distribution.
\item For each type of point estimate, there is a corresponding standard error.
\item A full list of standard error formulae will be attached in your examination paper.
\item The standard error for a  mean is
\[ S.E( \bar{x} )  = {\sigma \over \sqrt{n}} \]
However, we often do not know the value for $\sigma$. For practical purposes, we use the sample standard deviation $s$ as an estimate for $\sigma$ instead.
\[ S.E( \bar{x} )  = {s \over \sqrt{n}} \]
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Confidence Intervals for Sample Proportion}
Confidence Intervals may also be computed for \textbf{Sample Proportions}. \\The sample proportion is used to estimate the value of a population proportion. The sample proportion is denoted $\hat{p}$. The population proportion is denoted $\pi$.
\begin{itemize}
\item The structure of a confidence interval for sample proportion is
\[ \hat{p} \pm z_{(\alpha/2)} \times \mbox{S.E.}(\hat{p})\]

\item The standard error, in the case of sample proportions, is
\[ \mbox{S.E.}(\hat{p}) = \sqrt{\frac{\hat{p}\times (1-\hat{p})}{n}}\]
\item (When computing this interval with statistical software, it is common to enhance the solution using a \textbf{continuity correction} . This is not part of our syllabus. )
\end{itemize}
\end{frame}
%------------------------------------------------------------------------------%
\frame{
\frametitle{Point Estimates for proportions }
\textbf{Sample Percentage}

\[
\hat{p} = \frac{x}{n} \times 100\%
\]

\begin{itemize}
\item $\hat{p}$ - sample proportion.
\item $x$  - number of ``successes".
\item $n$  - the sample size.
\end{itemize}

}
%------------------------------------------------------------------------------%
\frame{
\frametitle{Point Estimates for proportions }

\begin{itemize}
\item Of a sample of 160 computer programmers, 56 reported than Python was their primary programming language.
\item Let $\pi$ be the proportion of all programmers who regard Python as their programming language. 
\item What is the point estimate for $\pi$?
\end{itemize}
\[
\hat{p} = \frac{x}{n} \times 100\% 
\]
\[
\hat{p} = {56 \over 160} = 35\%
\]
}
%------------------------------------------------------------------------------%
\frame{

\frametitle{ Standard Error for Proportions}

The standard error for proportions is computed using this formula.
\[
S.E. (\hat{p}) \;=\; \sqrt{ {\hat{p} \times (1-\hat{p} )\over n}}
\]


When expressing the proportion as a percentage, we adjust the standard error accordingly.
\[
S.E. (\hat{p}) \;=\; \sqrt{ {\hat{p} \times (100 -\hat{p} )\over n}}  [\%]
\]


}
\begin{frame}
\frametitle{ Sample Proportion : Example}


\begin{description}
\item[Point Estimate] The sample proportion is computed as follows
\[ \hat{p} = \frac{x}{n} = \frac{56}{160} = 0.35\]
\item[Quantile] We are asked for a 95\% confidence interval. The quantile is therefore
\[ z_{\alpha/2} =1.96\]
\item[Standard Error] The standard error, with sample size n=120 is computed as follows
\[ \mbox{S.E.}(\hat{p}) = \sqrt{\frac{\hat{p} \times (1-\hat{p})}{n}} =  \sqrt{\frac{0.35 \times 0.65}{160}}\]
\item (Full solution to follow on whiteboard)
\end{description}
\end{frame}

\begin{frame}
\frametitle{ Sample Proportion : Example}
\[ \mbox{S.E.}(\hat{p}) =  \sqrt{\frac{0.35 \times 0.65}{160}} = \sqrt{\frac{0.2275}{160}}\]

\[ \mbox{S.E.}(\hat{p}) = \sqrt{0.001421875} = 0.03770\]

\textbf{95\% Confidence Interval}
\[0.35 \pm (1.96 \times 0.0377) = (0.2761, 0.4239)\]
\end{frame}
%--------------------------------------------------%
\begin{frame}
\frametitle{Confidence Intervals for Sample Proportion}
Unlike confidence intervals for sample means, there is only one type of confidence interval when dealing with sample proportions.

\textbf{Optional}
\begin{itemize}

\item It is often easier to work in terms of percentages, rather than proportions.
If you are working in terms of percentages, remember to use the appropriate \textbf{\textit{complement value}} in the standard error formula (i.e. $100 - \hat{p}$)

\item The standard error, in the case of sample proportions, is
\[ \mbox{S.E.}(\hat{p}) = \sqrt{\frac{\hat{p}\times (100-\hat{p}}{n}}\]

\item Complement Values:
\begin{itemize} \item When working in terms of proportions, for the the value $\hat{p} =0.35$, the complement value is $1-\hat{p} =0.65$.
\item When working in terms of percentages, for the value $\hat{p} = 35\%$, the complement value is $100-\hat{p} = 65\%$.
\end{itemize}
\end{itemize}
\end{frame}








%------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Confidence Interval for a mean (1) }
Finally, an example to finish the class:
\begin{itemize}
\item For a given week, a random sample of 100 hourly employees selected from a very large number of
employees in a manufacturing firm has a sample mean wage of $\bar{x} = 280$ dollars, with a sample standard deviation of
$s = 40$ dollars.
\item Estimate the mean wage for all hourly employees in the firm with an interval estimate such that we can be 95
percent confident that the interval includes the value of the population mean.
\end{itemize}

\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Confidence Interval for a mean (2) }

\begin{itemize}
\item The point estimate in this case is the sample mean $\bar{x} = 280$ dollars.
\item We have a large sample (n=100) and the confidence level is $95\%$. Therefore the quantile  is 1.96.
\item The standard error is computed as follows:

\[ S.E( \bar{x} )  = {s \over \sqrt{n}}  =  {40 \over \sqrt{100}} = 4  \]
\item \textbf{Confidence Interval for mean}

\[
280 \pm (1.96 \times 4)  = (280 \pm 7.84) = (\;272.16\;,\;287.84\;)
\]

\end{itemize}
\end{frame}

\end{document}

%-----------------------------------------------------------%



%------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Small samples}
\begin{itemize} \item We indicated that use of the normal distribution in estimating a population mean is warranted
for any large sample ($n > 30$). \item For a small sample ($n \leq 30$) only if the population is normally distributed
\textbf{and} $\sigma$ is known, the standard normal distribution can be used compute quantiles. In practice,
this case is unusual.
\item Now we consider the situation in which the sample is small and the population is normally distributed,
but $\sigma$ is not known.
\end{itemize}
\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Student's $t-$distribution (1)}
\begin{itemize}
\item Student's $t-$distribution is a variation of the normal distribution, designed to factor in the increased uncertainty resulting from smaller samples.
\item The distribution is really a family of distributions, with
a somewhat different distribution associated with the degrees of freedom ($df$). For a confidence interval for the
population mean based on a sample of size n, $df = n - 1$.
\end{itemize}
\end{frame}

%------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Student's $t-$distribution (2)}
\begin{itemize}
\item With increasing
sample size, the $t-$distribution approaches the form of the standard normal (`Z') distribution.
\item In fact the standard normal distribution can be thought of as the $t-$distribution with $\infty$ degrees of freedom.
\item For computing quantiles, we will consider the `Z' distribution in this way.
\item For values of $n$ greater then 30, the difference between using $df = n-1$ and $df = \infty$ is negligible.

\item As this will be relevant later, remember that a confidence interval is a \textbf{two-tailed} procedure, i.e. $k=2$.
\end{itemize}
\end{frame}

%-----------------------------------------------------------%

\begin{frame}[fragile]
\frametitle{Student's $t-$distribution (3)}

\begin{itemize}
\item Student's t- values are determined using the \texttt{t} family of commands (e.g. \texttt{qt, pt, dt}).
\item To compute quantiles, use the code below.
\item The degrees of freedom must be additionally be specified. Degrees of freedom are computed as sample size minus one ($n-1$)
\item As the degrees of freedom gets larger and larger, the student t distribution converges to the Z distribution.

\end{itemize}

\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Confidence Interval for a Mean (Small Sample)}
\begin{itemize}
\item The mean operating life for a random sample of $n = 10$ light bulbs is $\bar{x} = 4,000$ hours, with the sample
standard deviation $s = 200$ hours. \item The operating life of bulbs in general is assumed to be approximately normally distributed.\item
We estimate the mean operating life for the population of bulbs from which this sample was taken, using a 95 percent
confidence interval as follows:

\[4,000\pm(2.262)(63.3)  = (3857,4143)\]

\item The point estimate is 4,000 hours. The sample standard deviation is 200 hours, and the sample size is 10. Hence \[S.E(\bar{x} ) = { 200 \over \sqrt{10}} = 63.3\]

\item From last slide, the t quantile with $df=9$ is 2.262.
\end{itemize}
\end{frame}

%------------------------------------------------------------------------%


% -- Lecture 8B
% -- Revise the Tables
% -- Sample Size Estimation for mean
% -- Example SSE for mean
% -- SSE for Proportion
% -- Example SSE for proportion
% -- Paired Test



%-------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size Estimation}

\begin{itemize} \item Recall the formula for margin of error, which we shall denote $E$.
\[  E = Q_{(1-\alpha)} \times \mbox{Std. Error}\]

\item $Q_{(1-\alpha)}$ denotes the quantile that corresponds to a $1-\alpha$ confidence level. (There is quite a bit of variation in notation in this respect.)
\item Also recall that the only way to influence the margin of error is to set the sample size accordingly.

\item Sample size estimation describes the selection of a sample size $n$ such that the margin of error does not exceed a pre-determined level $E$.
\end{itemize}
\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size Estimation for the Mean}

\begin{itemize}

\item The margin of error does not exceed a certain threshold $E$.
\[ E \geq Q_{(1-\alpha)} \times S.E.(\bar{x}), \]

\item which can be re-expressed as
\[E \geq Q_{(1-\alpha)} \times {\sigma \over \sqrt{n} }.\]

\item Divide both sides by $\sigma \times Q_{(1-\alpha)}$.
\[ \frac{E}{\sigma Q_{(1-\alpha)}} \geq {1 \over \sqrt{n} } \]

\item Square both sides

\[ \frac{E^2}{\sigma^2 Q_{(1-\alpha)}^2} \geq {1 \over n } \]


\end{itemize}
\end{frame}
%--------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size Estimation for the Mean}

\begin{itemize}
\item Square both sides

\[ \frac{E^2}{\sigma^2 Q^2_{(1-\alpha)}} \geq {1 \over n } \]

\item Invert both sides, changing the direction of the relational operator.

\[ \frac{\sigma^2 Q^2_{(1-\alpha)}}{E^2} \leq n \]


\item The sample size we require is the smallest value for $n$ which satisfies this identity.
\item The sample standard deviation $s$ may be used as an estimate for $\sigma$.
\item (This formula would be provided on the exam paper).
\end{itemize}


\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{SSE for the Mean: Example}

\begin{itemize}
\item An IT training company has developed a new certification program. The company wishes to estimate the average score of those who complete the program by self-study.  \item The standard deviation of the self study group is assumed to be the same as the overall population of candidates, ie. 21.2 points.
    \item How many people must be tested if the sample mean is to be in error by no more than 3 points, with 95\% confidence.
\end{itemize}
\end{frame}
%--------------------------------------------------------%
\begin{frame}
\frametitle{SSE for the Mean: Example}

\begin{itemize}
\item The sample size we require is the smallest value for $n$ which satisfies this identity.
\[ n \geq \frac{\sigma^2 Q^2_{(1-\alpha)}}{E^2}  \]
\item Remark: $1-\alpha$ = 0.95, therefore $Q_{(1-\alpha)}$ = 1.96. Also $E=3$ and $\sigma =21.2$.
\[ n \geq \frac{(21.2)^2 \times (1.96)^2}{3^2} \]
\item Solving, the required sample size is the smallest value of $n$ that satisfies
\[ n \geq 191.8410 \]
\item Therefore, the company needs to test 192 self-study candidates.
\end{itemize}
\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size Estimation for proportions}
We can also compute appropriate sample sizes for studies based on proportions.
\begin{itemize}
\item From before; \[ E \geq Q \times S.E.(\hat{p}). \]
(For the sake of brevity, we will just use the notation $Q$ for quantile.)

\item Divide both sides by Q.

\[ E \geq Q \times \sqrt{ {\pi(1-\pi)  \over n} }. \]

\end{itemize}
\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size Estimation for proportions}
\begin{itemize}
\item Remark: $E$ must be expressed in the same form as $\pi$, either as a proportion or as a percentage.
\item Remark : The standard error is maximized at $\pi = 0.50$,which is to say $\pi(1-\pi)$ can never exceed 0.25 ( or 25\%). Therefore the standard error is maximized at $\pi = 0.50$. To make the procedure as conservative as possible, we will use $0.25$ as our value for $\hat{p}_1 \times (1 - \hat{p}_1)$.
\item If we use percentages, $\pi \times (100-\pi)$ can not exceed 2500 (i.e $ 50 \times (100-50)=2500)$.

\[ E \geq Q \times \sqrt{{2500 \over n}}. \]


\end{itemize}

\end{frame}
%--------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size Estimation for proportions}

\begin{itemize}

\item Dive both sides by $Q$, the square both sides:

\[ \left({E\over Q}\right)^2 \geq {2500 \over n}. \]

\item Invert both sides, changing the direction of the relational operator, and multiply both sides by $2500$.

\[ \left({Q\over E}\right)^2 \times 2500 \leq n. \]

\item The sample size we require is the smallest value for $n$ which satisfies this identity. (This formula would be provided on the exam paper, but without the maximized standard error).
\end{itemize}
\end{frame}
%--------------------------------------------------------%
\begin{frame}
\frametitle{SSE for proportions: Example}
\begin{itemize}
\item An IT journal wants to conduct a survey to estimate the true proportion of university students that own laptops.
\item The journal has decided to uses a confidence level of $95\%$, with a margin of error of $2\%$.
\item How many university students must be surveyed?
\end{itemize}
\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{Sample Size estimation for proportions}

\begin{itemize}
\item Confidence level = 0.95. Therefore the quantile is $Q_{(1-\alpha)} = 1.96$
\item Using the formula: \[ n \geq \left({1.96 \over 2 }\right)^2 \times 2500  \]
\item The required sample size is the smallest value for $n$ which satisfies this identity: \[ n \geq 2401  \]
\item The required sample size is therefore 2401.
\end{itemize}
\end{frame}


%--------------------------------------------------------%
\begin{frame}
\frametitle{Independent Samples (New Section)}
\begin{itemize}
\item Two samples are referred to as independent if the observations in one sample are not in any way related to the observations in the other. \item This is also used in cases where one randomly assign subjects to two groups, i.e. in give first group treatment A and the second group treatment B and compare the two groups.
\item Often we are interested in the difference between the mean value of some parameter for both groups.
\end{itemize}
\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{Independent Samples}

The approach for computing a confidence interval for the difference of the means of two independent samples,  described shortly, is valid whenever the following conditions are met:

\begin{itemize}
\item Both samples are simple random samples.
\item The samples are independent.
\item Each population is at least 10 times larger than its respective sample. (Otherwise a different approach is required).
\item The sampling distribution of the difference between means is approximately normally distributed
\end{itemize}

\end{frame}

%---------------------------------------------------------%
\begin{frame}
\frametitle{Difference Of Two Means}
%-http://onlinestatbook.com/chapter8/difference_means.html
In order to construct a confidence interval, we are going to make three assumptions:

\begin{itemize}
\item The two populations have the same variance. This assumption is called the assumption of homogeneity of variance.
\item For the time being, we will use this assumption. Later on in the course, we will discuss the validity of this assumption for two given samples.
\item The populations are normally distributed.
\item Each value is sampled independently from each other value.
\end{itemize}
\end{frame}

%---------------------------------------------------------%
\begin{frame}
\frametitle{Computing the Confidence Interval}

\begin{itemize}
\item As always the first step is to compute the point estimate. For the difference of means for groups $X$ and $Y$, the point estimate is simply the difference between the two means i.e. $\bar{x} - \bar{y}$.

\item As we have seen previously, sample size has a bearing in computing both the quantile and the standard error.
For two groups, we will use the aggregate sample size ($n_x+n_y)$ to compute the quantile. (For the time being we will assume, the aggregate sample size is large ($n_x+n_y)> 30$.)

\item Lastly we must compute the standard error $S.E.(\bar{x}-\bar{y})$. The formula for computing standard error for the difference of two means, depends on whether or not the aggregate sample size is large or not. For the case that the sample size is large, we use the following formula (next slide).
\end{itemize}
\end{frame}

%---------------------------------------------------------%
\begin{frame}
\frametitle{Computing the Confidence Interval}
Standard Error for difference of two means (large sample)

\[ S.E.(\bar{x}-\bar{y}) = \sqrt{\frac{s^2_x}{n_x} + \frac{s^2_y}{n_y}} \]

\begin{itemize}
\item $s^2_x$ and $s^2_x$ is the variance of samples $X$ and $Y$ respectively.
\item $n_x$ and $n_y$ is the sample size of both samples.\bigskip

\item For small samples, the degrees of freedom is $df = n_x + n_y - 2$. If the sample size $n \leq 32$, we can find appropriate $t-$quantile, rather than assuming it is a $z-$quantile.
\end{itemize}
\end{frame}

%---------------------------------------------------------%
\begin{frame}
\frametitle{CI for Difference in Two Means}
A research company is comparing computers from two different companies, X-Cel and Yellow, on the basis of energy consumption per hour. Given the following data, compute a $95\%$ confidence interval for the difference in energy consumption.
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Type & sample size & mean & variance \\ \hline
X-cel & 17 & 5.353 & 2.743 \\ \hline
Yellow & 17 & 3.882 & 2.985 \\ \hline
\end{tabular}
\end{center}
Remark: It is reasonable to believe that the variances of both groups is the same. Be mindful of this.

\end{frame}
%---------------------------------------------------------%
\begin{frame}
\begin{itemize}
\item Point estimate : $\bar{x} - \bar{y}$ = 1.469
\item Standard Error: 0.5805
\[ S.E.(\bar{x}-\bar{y}) = \sqrt{\frac{2.743}{17} + \frac{2.985}{17}} = \sqrt{0.33698} \]
\item Quantile : 1.96 (Large sample, with confidence level of $95\%$.)
\end{itemize}

\[ 1.469  \pm (1.96 \times 0.5805) = (0.3321,2.607) \]


This analysis provides evidence that the mean consumption level per hour for X-cel is higher than the mean consumption level per hour for Yellow, and that the difference between means in the population is likely to be between 0.332 and 2.607 units.
\end{frame}

%---------------------------------------------------------%
\begin{frame}

\frametitle{Computing the Confidence Interval}
Standard Error for difference of two means (small aggregate sample)

\[ S.E.(\bar{x}-\bar{y}) = \sqrt{  s^2_p \left({1\over n_x}+{1\over n_y} \right)} \]

Pooled Variance $s^2_p$ is computed as:

\[ s^2_p = \frac{(n_x-1)s^2_x + (n_y-1)s^2_y}{(n_x-1) + (n_y-1)} \]
\end{frame}
%---------------------------------------------------------%
\begin{frame}
\frametitle{CI for Difference in Two Means}
From the previous example (comparing X-cel and Yellow) lets compute a 95\% confidence interval when the sample sizes are $n_x=10$ and $n_y=12$ respectively. (Lets assume the other values remain as they are.)
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
Type & sample size & mean & variance \\ \hline
X-cel & 10 & 5.353 & 2.743 \\ \hline
Yellow & 12 & 3.882 & 2.985 \\ \hline
\end{tabular}
\end{center}
The point estimate $\bar{x} - \bar{y}$ remains as 1.469. Also we require that both samples have equal variance. As both $X$ and $Y$ have variances at a similar level, we will assume equal variance.

\end{frame}
%---------------------------------------------------------%
\begin{frame}

\frametitle{Computing the Confidence Interval}
\begin{itemize} \item Pooled variance $s^2_p$ is computed as:

\[ s^2_p = \frac{(10-1)2.743 + (12-1)2.985}{(10-1) + (12-1)}  = \frac{57.52}{20} = 2.87\]

\item Standard error for difference of two means is therefore

\[ S.E.(\bar{x}-\bar{y}) = \sqrt{  2.87 \left({1\over 10}+{1\over 12} \right)} = 0.726 \]

\item The aggregate sample size is small i.e. 22. The degrees of freedom is $n_x+n_y-2 = 20$.
From Murdoch Barnes tables 7, the quantile for a $95\%$ confidence interval is 2.086.

\item The confidence interval is therefore
\[ 1.469  \pm (2.086 \times 0.726) = 1.4699 \pm 1.514 =  (-0.044, 2.984 )  \]
\end{itemize}
\end{frame}

%--------------------------------------------------------%
\begin{frame}
\frametitle{Difference in proportions}
We can also construct a confidence interval for the difference between two sample proportions, $\pi_1 - \pi_2$. The point estimate is the difference in sample proportions for tho both groups , $\hat{p}_1- \hat{p}_2$.\\\bigskip
\textbf{Estimation Requirements}
The approach described in this lesson is valid whenever the following conditions are met:

\begin{itemize}
\item Both samples are simple random samples.
\item The samples are independent.
\item Each sample includes at least 10 successes and 10 failures.
\item The samples comprises less than 10\% of their respective populations.
\end{itemize}
\end{frame}


%--------------------------------------------------------%

\begin{frame}
\frametitle{Standard Error for Difference of Proportions}

\[ S.E. (\hat{p}_1 - \hat{p}_2) =
\sqrt{ \left[{\hat{p}_1 \times (1 - \hat{p}_1) \over n_1}\right] + \left[{\hat{p}_2 \times (1 - \hat{p}_2) \over n_2}\right] } \]
\begin{itemize}
\item $\hat{p}_1$ and $\hat{p}_2$ are the sample proportions of groups 1 and 2 respectively.
\item $n_1$ and $n_2$ are the sample sizes of groups 1 and 2 respectively.
\end{itemize}
N.B. This formula will be provided in the exam paper. Also, there is no accounting for small samples.
\end{frame}
%--------------------------------------------------------%

\begin{frame}
\frametitle{ Difference of Proportions : Example}
\begin{itemize} \item
A study finds that a percentage of $40\%$ of IT users out of a random sample of 400 in a large
community preferred one web browser to all others. \item In another large community, $30\%$ of IT users out of a random sample
of 300 prefer the same web browser. \item Compute a 95 percent confidence interval for the difference in the proportion of IT users who prefer this particular web browser. \end{itemize}
\end{frame}

%--------------------------------------------------------%

\begin{frame}
\frametitle{Confidence Interval}
\textbf{Compute the standard Error}

\[ S.E. (\hat{p}_1 - \hat{p}_2) =
\sqrt{ \left[{\hat{p}_1 \times (1 - \hat{p}_1) \over n_1}\right] + \left[{\hat{p}_2 \times (1 - \hat{p}_2) \over n_2}\right] } \]

\[ S.E. (\hat{p}_1 - \hat{p}_2) =
\sqrt{ \left[{40 \times 60 \over 400}\right] + \left[{30 \times 70 \over 300}\right] }  = \sqrt{ \left[{2400 \over 400}\right] + \left[{2100\over 300}\right] } \]

\[ S.E. (\hat{p}_1 - \hat{p}_2)
= \sqrt{ 6 + 7 } = 3.6\% \]

\end{frame}


\begin{frame}
\frametitle{Confidence Interval}
\begin{itemize}
\item The point estimate is the difference in two proportions i.e. $\hat{p}_1 - \hat{p}_2$ = $40 \% - 30 \% = 10 \%$
\item We have a large sample, and the confidence level is $95\%$. Therefore the quantile is 1.96.
\item We can now compute the confidence interval for the difference of proportions:
\[ 10\% \pm (1.96 \times 3.6 \%)  =\; 10\% \pm 7.05 \% = \;(2.95\%, 17.05\%) \]

\end{itemize}
\end{frame}


\end{document}













%--------------------------------------------------------%

\begin{frame}
\begin{itemize}
\item SE = $\sqrt{ [p_1 \times (1 - p_1) / n_1] + [p_2 \times (1 - p_2) / n_2] } $
\item SE = $\sqrt{ [0.40 \times 0.60 / 400] + [0.30 \times 0.70 / 300] } $
\item SE  = $\sqrt{[ (0.24 / 400) + (0.21 / 300) ]}$ = $\sqrt{(0.0006 + 0.0007)}$ = \sqrt{0.0013} = 0.036
\end{itemize}
\end{frame}


%--------------------------------------------------------%

\begin{frame}
\frametitle{Mean Difference Between Matched Data Pairs}


The approach described in this lesson is valid whenever the following conditions are met:

\begin{itemize}
\item The data set is a simple random sample of observations from the population of interest.
\item Each element of the population includes measurements on two paired variables (e.g., x and y) such that the paired difference between x and y is: d = x - y.
\item The sampling distribution of the mean difference between data pairs (d) is approximately normally distributed.
\end{itemize}



The observed data are from the same subject or from a matched subject and are drawn from a population with a normal distribution
does not assume that the variance of both populations are equal



\end{frame}

%---------------------------------------------------------------------------------------------------------------%
\begin{frame}
\frametitle{Computing the Case Wise Differences}
\begin{center}
\small
\begin{tabular}{|c||c|c|c|c|} \hline
Student & Before & After & Difference $(d_i)$ & $ (d_i -\bar{d})^2$ \\\hline
1 &90& 95& 5& 16 \\\hline
2 &85& 89& 4& 9 \\\hline
3 &76 &73 &-3 &4 \\\hline
4 &90& 92& 2& 1 \\\hline
5 &91 &92 &1 &0 \\\hline
6 &53 &53& 0& 1 \\\hline
7 &67 &68 &1 &4 \\\hline
8 &88 &90 &2 &9 \\\hline
9 &75 &78 &3 &16\\\hline
10 &85& 89 &4& 25 \\\hline
\end{tabular}
\end{center}

\end{frame}

%---------------------------------------------------------------------------------------------------------------%


\begin{frame}
\frametitle{Computing the Case Wise Differences}
Compute the mean difference

\[ \bar{d}  = {\sum{d_i} \over n } = { 3+6 \over 8} \]

Compute the variance of the differences.

\[ s^2_{d}  ={\sum(d_i -\bar{d})^2 \over n-1 } =  { 3+6 \over 9} \]

\end{frame}

%--------------------------------------------------------%

\begin{frame}
\frametitle{Difference of Two Means}
\begin{itemize}
\item
\item
\end{itemize}
\end{frame}
%---------------------------------------------------------%

\begin{frame}
\frametitle{How a paired t test works}
\begin{itemize}
\item The paired t test compares two paired groups.
\item It calculates the difference between each set of pairs, and analyzes that list of differences based on the assumption that the differences in the entire population follow a Gaussian distribution.
\item First we calculate the difference between each set of pairs, keeping track of sign.
\item If the value in column B is larger, then the difference is positive.
If the value in column A is larger, then the difference is negative.
\item The t ratio for a paired t test is the mean of these differences divided by the standard error of the differences. If the t ratio is large (or is a large negative number), the P value will be small. The number of degrees of freedom equals the number of pairs minus 1. Prism calculates the P value from the t ratio and the number of degrees of freedom.
\end{itemize}
\end{frame}
%---------------------------------------------------------%
\begin{frame}
\[ ( \bar{X} - \bar{Y} ) \pm \left[ \mbox{Quantile } \times S.E(\bar{X}-\bar{Y}) \right] \]
\begin{itemize}
\item If the combined sample size of X and Y is greater than 30, even if the individual sample sizes are less than 30, then we consider it to be a large sample.
\item The quantile is calculated according to the procedure we met in the previous class.
\end{itemize}
\end{frame}
%---------------------------------------------------------%
\begin{frame}\begin{itemize}
\item Assume that the mean ($\mu$) and the variance ($\sigma$) of the distribution
of people taking the drug are 50 and 25 respectively and that the mean ($\mu$)
and the variance ($\sigma$) of the distribution of people not taking the drug are
40 and 24 respectively.
\end{itemize}
\end{frame}





%---------------------------------------------------------%
\begin{frame}
\frametitle{Difference in Two means}
For this calculation, we will assume that the variances in each of the two populations are equal. This assumption is called the assumption of homogeneity of variance.

The first step is to compute the estimate of the standard error of the difference between means ().

\[ S.E.(\bar{X}-\bar{Y}) = \sqrt{\frac{s^2_x}{n_x} + \frac{s^2_y}{n_y}} \]

\begin{itemize}
\item $s^2_x$ and $s^2_x$ is the variance of both samples.
\item $n_x$ and $n_y$ is the sample size of both samples.
\end{itemize}
The degrees of freedom is $n_x + n_y -2$.
\end{frame}



\end{document}
\end{document}

























%-----------------------------------------------------------%

\begin{frame}
\frametitle{CI for Proportion: Example (1)}

\begin{itemize}
\item $\hat{p}  = 0.62$
\item Sample Size $n=250$
\item Confidence level $1-\alpha$ is $95\%$
\end{itemize}

\end{frame}
%-----------------------------------------------------------%

\begin{frame}\frametitle{CI for Proportion: Example (2)}

\begin{itemize}
\item First, lets determine the quantile.
\item The sample size is large, so we will use the Z distribution.
\item (Alternatively we can uses the $t-$ distribution with $\infty$ degrees of freedom.
\end{itemize}

\end{frame}


%------------------------------------------------------------------------------%
\begin{frame}
Although the sample mean is useful as an unbiased estimator of the population mean, there is no way of
expressing the degree of accuracy of a point estimator. In fact, mathematically speaking, the probability that the
sample mean is exactly correct as an estimator of the population mean is $P = 0$.
\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
A confidence interval for the
mean is an estimate interval constructed with respect to the sample mean by which the likelihood that the interval
includes the value of the population mean can be specified.

The \emph{level of confidence} associated with a confidence interval indicates the long-run percentage
 of such intervals which would include the parameter being estimated.
\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
\begin{itemize}
\item Confidence intervals for the mean typically are constructed with the unbiased estimator $\bar{x}$ at the midpoint
of the interval.

\item The $\pm Z \sigma_x$ or $\pm Z s_x$ frequently is called the \textbf{\emph{margin of error}} for the confidence interval.
\end{itemize}
\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
We indicated that use of the normal distribution in estimating a population mean is warranted
for any large sample ($n > 30$), \textbf{and} for a small sample ($n \leq 30$) only if the population is normally distributed
and $\sigma$ is known.
\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}
\begin{itemize}
\item Now we consider the situation in which the sample is small and the population is normally distributed,
but $\sigma$ is not known.
\item The distribution is a family of distributions, with
a somewhat different distribution associated with the degrees of freedom ($df$). For a confidence interval for the
population mean based on a sample of size n, $df = n - 1$.
\end{itemize}
\end{frame}
%------------------------------------------------------------------------------%
\begin{frame}\frametitle{Student t distribution}
\begin{itemize}

\end{itemize}
\end{frame}
%------------------------------------------------------------------------------%
\frame{

\frametitle{Computing the Standard Error}

\[
S.E. (\hat{p}) \;=\; \sqrt{ {\hat(p) \times (100 -\hat{p} )\over n}}
\]



}

%
------------------------------------------------------------------------------%

\frame{
\[
\hat{p} = {144/200}  \times 100\%  = 0.72 \times 100\%.  = 72%
\]

$100\% - \hat{p} = 100\% - 72\% = 28\% $

}


%------------------------------------------------------------------------------%
\frame{
\textbf{Computing the Standard Error}

\[
S.E. (\hat{p}) \;=\; \sqrt{ {72 \times 28 \over 200 }}
\]


}
%------------------------------------------------------------------------------%

\end{document}


%-----------------------------------------------------------%

% Confidence Interval for a Proportion
% One Sample
%------------------------------------------------------------------------------%



