\documentclass{beamer}
% http://www.hss.caltech.edu/~mshum/stats/lect2.pdf

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}

\begin{document}
	
	\begin{frame}
		\bigskip
		{
			\huge
			\[ \mbox{Expected Values of Random Variables}\]
			\Large
			\[ \mbox{Example Exercise}\]
			\bigskip
			\Large
			\[ \mbox{www.MathsResource.com}\]
		}
		
	\end{frame}
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		If the random variable $Z$ has a distribution which is standard normal, show that the expected value of $e^{sZ}$ is given as follows:
		
		{
			\LARGE
			\[E(e^{sZ})  =  e^{\frac{s^2}{2}}\] 
		}
		
		
	\end{frame}
	%---------------------------------------------------- %
	
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\begin{itemize}
			\item In general, the expected value is computed using this formula
			{
				\LARGE
				\[ E(X) =  \int_{-\infty}^{\infty}  x \times f(x) dx   \]
			}
			\item The expected value of a \textbf{\textit{transformed}} random variable is computed using this formula
			{
				\LARGE
				\[ E( tf(X) ) =  \int_{-\infty}^{\infty}  tf(x) \times f(x) dx   \]
			}
		\end{itemize}
		
	\end{frame}
	%---------------------------------------------------- %
	
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\begin{itemize}
			\item 
			The probability density function for the standard normal distribution is
			{
				\Large
				\[f(x, \mu, \sigma) = \frac{1}{\sigma\sqrt{2\pi}} e^{ -\frac{(x-\mu)^2}{2\sigma^2} }\]}
			\item 
			The probability density function for the standard normal distribution is
			{
				\Large
				\[f(z) = f(x, \mu= 0, \sigma=1) = \frac{1}{\sqrt{2\pi}} e^{ -{x \over 2}^2 }\]
			}
		\end{itemize}
	\end{frame}
	%---------------------------------------------------- %
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\vspace{-4cm}
		
		
		
		{
			\LARGE
			\[ E( e^{sZ} ) =  \int_{-\infty}^{\infty}  e^{sx} \;\times\; \frac{1}{\sqrt{2\pi}} \;e^{ -{x \over 2}^2 }\]
		}
		
		
	\end{frame}
	%---------------------------------------------------- %
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\vspace{-4cm}
		
		
		
		{
			\LARGE
			\[ E( e^{sZ} ) =  \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty}   e^{ \big[sx-\frac{(x)^2}{2} \big]} dx   \]
		}
		
	\end{frame}
	%---------------------------------------------------- %
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\vspace{-4cm}
		
		
		
		{
			\LARGE
			\[ E( e^{sZ} ) =  e^{{s^2\over 2}} \; \times\; \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{ \big[-\frac{(x-s)^2}{2} \big]} dx   \]
		}
		
	\end{frame}
	%---------------------------------------------------- %
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\vspace{-3cm}
		\textbf{Mathematical Identity}
		\begin{itemize}
			\item Proven in a separate video
		\end{itemize}
		{
			\LARGE
			\[\int_{-\infty}^{\infty} e^{-{y\over 2}^2}dy  = \sqrt{2\pi}\]
			
		}
	\end{frame}
	
	%---------------------------------------------------- %
	\begin{frame}
		\frametitle{Expected Values of Random Variables}
		\Large
		\vspace{-2.5cm}
		
		
		
		{
			\LARGE
			\[ E( e^{sZ} ) =  e^{{s^2\over 2}} \; \times\; \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{ \big[-\frac{(x-s)^2}{2} \big]} dx \]
			
			
			\[ E( e^{sZ} ) =  e^{{s^2\over 2}} \; \times\; \frac{1}{\sqrt{2\pi}} \big[\sqrt{2\pi} \big] \]
		}
		
	\end{frame}
	
	\begin{frame}
		Suppose an electronics assembly subcontractor recieves resistors from two suppliers A and B
		
		Supplier A supplies 80% of the resistors
		
		P(A) = 0.80 probability that a randomly chosen resistor comes from A
		
		Supplier B supplies 20% of the resistors
		
		P(B) = 0.20 probability that a randomly chosen resistor comes from B
		
	\end{frame}
	%-----------------------------------------------------%
	\begin{frame}
		\Large
		\begin{itemize}
			\item 1% of the resistors supplied by A are faulty (i.e. resistor fails the final test)
			\item 3% of the resistors supplied by B are faulty 
		\end{itemize}
	\end{frame}
	%-----------------------------------------------------%
	\begin{frame}
		
		Qeustion: What is the probability that a randomly selected resistor fails the final test?
		
		Compute P(F) 
		
	\end{frame}
	%------------------------------------------------------%
	
	\begin{frame}
		\Large
		P(F) = P(FandA) + P(FandB)
		
	\end{frame}
	
\end{document}




\begin{frame}
	\frametitle{Probability Distribution}
\end{frame}
%--------------------------------------%

\begin{frame}
	
	
\end{frame}
%---------------------------------------%

A probability distribution is a mathematical approach to quantifying uncertainty.

There are two main classes of probability distributions: Discrete and continuous. 

Discrete distributions describe variables that take on discrete values only (typically the positive integers), while continuous 
distributions describe variables that can take on arbitrary values in a continuum (typically the real numbers).








%---------------------------------------%


\begin{frame}
	
	
	
	Binomial Distribution
	
	A manufacturer of hospital equipment knows from experience that 5% of the production will have some type of minor default, and will require adjustment.
	
	Number of independent trials    n
	
	Probability of a "success" p
	
	
	
	
	
	\begin{frame}
		\frametitle{Poisson Distribution}
	\end{frame}
	%--------------------------------------%
	
	\begin{frame}
		
		
	\end{frame}
	%---------------------------------------%
	
	A basic introduction to the concept
	
	Example
	
	Certain events happen at unpredictable intervals. But for some reason, no matter how recent or long ago last event was, the probability that another event will occur within the next hour is exactly the same (say, 10%). The same holds for any other time interval (say, second). Moreover, the number of events within any given time interval is statistically independent of numbers of events in other intervals that do not overlap the given interval. Also, two events never occur simultaneously.
	
	Then the number of events per day is Poisson distributed.
	
	%---------------------------------------%
	Formal definition
	
	Let X be a stochastic variable taking non-negative integer values with probability density function
	
	\[ P(X=k)=f(k)= e^{-\lambda} \frac{\lambda ^k}{k!}.\] 
	Then X follows the Poisson distribution with parameter \lambda.
	
	%---------------------------------------%
	Characteristics of the Poisson distribution
	
	If X is a Poisson distribution stochastic variable with parameter \lambda, then
	
	\begin{itemize}
		\item The expected value $E[X]=\lambda$
		\item The variance $Var[X]=\lambda$
	\end{itemize}
	%----------------------------------------%
	
	
	
	\begin{frame}
		
		\huge
		\[ \mbox{The Normal Distribution} \]
		\Large
		\[ \mbox{Symmetric Intervals} \]
		
		
		
	\end{frame}
	%---------------------------------------------------%
	\begin{frame}
		
		
		Symmetric Intervals
		
		\[ P( -z \leq Z \leq z) \]
		
		
	\end{frame}
	%---------------------------------------------------%
	\begin{frame}
		
		
	\end{frame}
	%---------------------------------------------------%
	
	\begin{frame}
		
		\huge
		\[ \mbox{The Normal Distribution} \]
		\Large
		\[ \mbox{The Symmetry Rule} \]
		
		
		
	\end{frame}
	%---------------------------------------------------%
	
	\begin{frame}
		
		\huge
		\[ \mbox{The Normal Distribution} \]
		\Large
		\[ \mbox{The Symmetry Rule} \]
		
	\end{frame}
	%---------------------------------------------------%
	\begin{frame}
		\frametitle{Normal Distribution : The Symmetry Rule}
		\Large
		From statistical tables, we could determine the following:
		\begin{itemize}
			\item $P(Z \leq 1.5) $
			\item $P(Z \geq 1.5) $
		\end{itemize}
		
	\end{frame}
	%---------------------------------------------------%
	\begin{frame}
		\frametitle{Normal Distribution : The Symmetry Rule}
		\Large
		
		Consider the normally distributed random variable $X$
		
		\[ X \sim \mathcal{N}(\mu=1000,\sigma^2 = 2500) \]
		
		Paramters:
		\begin{itemize}
			\item $\mu =1000$
			\item $\sigma =50$
		\end{itemize}
		Questions
		
		\begin{itemize}
			\item $P(X \leq 925)$
			\item $P(X \geq 925)$
		\end{itemize}
		
		
	\end{frame}
	%---------------------------------------------------%
	\begin{frame}
		\frametitle{Normal Distribution : The Symmetry Rule}
		\textbf{Z-score}
		\[ z =\frac{x - \mu}{\sigma}\]
		
		\[ X \sim \mathcal{N}(\mu=1000,\sigma^2 = 2500) \]
		
		\begin{itemize}
			\item Mean $\mu= 1000$
			\item Standard Deviation $\sigma = 50$
		\end{itemize}
	\end{frame}
	%---------------------------------------------------%
	\begin{frame}
		\frametitle{Normal Distribution : The Symmetry Rule}
		
		\[ P(X \leq 925)  = P(Z \leq -1.5) \]
		
		Applying the Symmetry Rule
		\[ P(Z \leq -1.5) = P(Z \geq 1.5) = 0.0668\]
		
		Theerefore we can say 
		\[ P(X \leq 925) = 0.0668 \]
	\end{frame}
	%---------------------------------------------------%
	
	\frametitle{Standardizing normal random variables}
	
	As a consequence of Property 1, it is possible to relate all normal random variables to the standard normal.
	
	If $X \sim N(\mu, \sigma^2)$, then
	
	Z = \frac{X - \mu}{\sigma} \!
	is a standard normal random variable: Z \sim N(0,1). An important consequence is that the cdf of a general normal distribution is therefore
	
	\Pr(X \le x)
	=
	\Phi
	\left(
	\frac{x-\mu}{\sigma}
	\right)
	=
	\frac{1}{2}
	\left(
	1 + \operatorname{erf}
	\left(
	\frac{x-\mu}{\sigma\sqrt{2}}
	\right)
	\right)
	.
	
\end{frame}
%-------------------------------------------------------------------------%
\begin{frame}
	
	Conversely, if Z is a standard normal distribution, Z \sim N(0,1), then
	
	X = \sigma Z + \mu
	is a normal random variable with mean \mu and variance \sigma^2.
	
	The standard normal distribution has been tabulated (usually in the form of value of the cumulative distribution function F), and the other normal distributions are the simple transformations, as described above, of the standard one. Therefore, one can use tabulated values of the cdf of the standard normal distribution to 
	find values of the cdf of a general normal distribution.
\end{frame}	
\end{document}
%------------------------------------------------------------------------------------------------%
%------------------------------------------------------------------------------------------------%
%------------------------------------------------------------------------------------------------%
\chapter{Probability}
\subsection{Statistics}

\begin{enumerate}
	\item Sample mean
	\begin{equation*}
		\bar{x}=\frac{\sum x_{i}}{n}.
	\end{equation*}
	
	\item Sample standard deviation
	\begin{equation*}
		s=\sqrt{\frac{\sum \left( x_{i}-\bar{x}\right) ^{2}}{%
				n-1}}.
	\end{equation*}
	
	\item Conditional probability:
	\begin{equation*}
		P(B|A)=\frac{P\left( A\text{ and }B\right) }{P\left( A\right) }.
	\end{equation*}
	
	
	
	
	
	
\end{enumerate}

\section{Probability Formulae}

\begin{itemize}
	
	\item Conditional probability:
	\begin{equation*}
		P(B|A)=\frac{P\left( A\text{ and }B\right) }{P\left( A\right) }.
	\end{equation*}
	
	
	\item Bayes' Theorem:
	\begin{equation*}
		P(B|A)=\frac{P\left(A|B\right) \times P(B) }{P\left( A\right) }.
	\end{equation*}
\end{itemize}
\subsection*{Section 3 : Probability}

How to Compute Probability: Equally Likely Outcomes
Sometimes, a statistical experiment can have n possible outcomes, each of which is equally likely. Suppose a subset of r outcomes are classified as "successful" outcomes.

The probability that the experiment results in a successful outcome (S) is:

P(S) = ( Number of successful outcomes ) / ( Total number of equally likely outcomes ) = r / n

Consider the following experiment. An urn has 10 marbles. Two marbles are red, three are green, and five are blue. If an experimenter randomly selects 1 marble from the urn, what is the probability that it will be green?

In this experiment, there are 10 equally likely outcomes, three of which are green marbles. Therefore, the probability of choosing a green marble is 3/10 or 0.30.

\begin{itemize}
\item Conditional probability
\item Independent events
\item Repeated independent events
\end{itemize}


%------------------------------------------------%
\section{Mutually Exclusive Events}
Mutually exclusive events are events that cannot happen at the same time.
\[ P(A and B) = P(A) + P(B) \]

%------------------------------------------------------------------------------------------------%
%------------------------------------------------------------------------------------------------%
%------------------------------------------------------------------------------------------------%
\section{Quantiles}

The quantile (this term was first used by Kendall, 1940) of a distribution of values is a number xp such that a proportion p of the population values are less than or equal to xp. For example, the .25 quantile (also referred to as the 25th percentile or lower quartile) of a variable is a value (xp) such that $25\%$ (p) of the values of the variable fall below that value.

Similarly, the $0.75$ quantile (also referred to as the 75th percentile or upper quartile) is a value such that $75\%$ of the values of the variable fall below that value and is calculated accordingly.

See



%------------------------------%
\section{Probability Distribution}

A statistical function that describes all the possible values and likelihoods that a random variable can take within a given range. This range will be between the minimum and maximum statistically possible values, but where the possible value is likely to be plotted on the probability distribution depends on a number of factors, including the distributions mean, standard deviation, skewness and kurtosis.



\section {The binomial distribution }

The binomial distribution  is a discrete probability distribution that is applicable as a model for decisionmaking
situations in which a sampling process can be assumed to conform to a Bernoulli process. A Bernoulli
process is a sampling process in which
(1) Only two mutually exclusive possible outcomes are possible in each trial, or observation. For
convenience these are called success and failure.
(2) The outcomes in the series of trials, or observations, constitute independent events.
(3) The probability of success in each trial, denoted by p, remains constant from trial to trial. That is,
the process is stationary.
The binomial distribution can be used to determine the probability of obtaining a designated number of
successes in a Bernoulli process. Three values are required: the designated number of successes (X); the number
of trials, or observations (n); and the probability of success in each trial (p). Where $q = (1 - p)$, the formula for
determining the probability of a specific number of successes X for a binomial distribution is

\[ \mbox{Formula} \]




\section{Normal Distribution: Worked Examples}

MA4413    Computer Maths 3     January 2007


Q5. a) Assume that the amount of wine poured into a bottle has a normal distribution with a mean of 750ml and a variance of 144ml$^2$.

1.   Calculate the probability that a bottle contains more than 765ml. (2 marks)
2.   Calculate the probability that a bottle contains between 744ml and 759ml. (3 marks)

MA4403    Computer Maths 3     January 2006

A machine fills bags with animal feed. The nominal weight of a bag is 50kg.
Because random variations the weight of a filled bag is normally distributed
$N(\mu, \sigma^2)$. The variance ($\sigma^2$) is known to be 0.01kg$^2$ and $\mu$ is set by the
operator to a particular value.

(i) If ? = 50kg calculate the probability of a bag containing less than
49.95kg?
(ii) Calculate the value of "?" such that only $2\%$ of the output are under the
nominal weight?



MA4004     Engineering Statistics    SPRING 2008


a)	The amount of beer in a bottle has a normal distribution with mean 500ml and variance 25ml2.
i)	Calculate the probability that the amount of beer in the bottle is between 498ml and 504ml.
ii)	What volume is exceeded by $20\%$ of the bottles?
(6 marks)

%--------------------------------------------------------------------------------------%




%---------------------------------%
\section*{Question 1 : Probability Distribution}

\subsection*{Introduction}{\LARGE Consider playing a game in which you are winning when a \textbf{\emph{fair die}} is showing `six'
	and losing otherwise.}
\subsection*{Part 1}{\LARGE If you play three such games in a row, find the probability mass function (pmf) of the number
	X of times you have won.}

{\LARGE
	\begin{itemize}
		\item Firstly: what type of probability distribution is this?
		
		\item Is this the distribution \textbf{\emph{discrete}} or  \textbf{\emph{continuous}}?
		
		\item The outcomes are whole numbers - so the answer is discrete.
		
		\item So which type of discrete distribution? (We have two to choose from. See first page of formulae)
		
		
		\item \textbf{Binomial:} characterizing the number of \textbf{\emph{successes}} in a series of \textbf{\emph{$n$ independent trials}}, with the \textbf{\emph{probability of a success}} in each trial being $p$.
		
		\item \textbf{Poisson:}  characterizing the \textbf{\emph{number of occurrences}} in a \textbf{\emph{unit space}} (i.e. a unit length, unit area or unit volume, or a unit period in time), where $\lambda$ is the the number of occurrences per unit space.
		
	\end{itemize}
}

\subsection{The Standard Normal Distribution}



\subsection{Standardisation Formula}

\begin{equation}
	Z = ( X - \mu ) / \sigma
\end{equation}

%----------------------------------------------------------------%
\section*{Uniform Distribution: Exercise 24}

Use the uniform distribution to simulate 100 throws of two dice. The outcome is the combined values of both dice. Use the appropriate R command to discretize values.
\begin{itemize}
	\item  What is the mean and standard deviation of the outcomes?
	\item  Make a stem-and-leaf plot of the outcomes.
	\item Make a histogram of the outcomes. (hint: use breaks =seq(1.5,12.5))
\end{itemize}



\subsection{Example 2}
A machine produces components whose thicknesses are normally
distributed with a mean of 0.40 cm and a standard deviation of 0.02 cm.
Components are rejected if they have a thickness outside the range 0.38 cm
to 0.41 cm.
(i) What is the probability that a component will have a thickness
exceeding 0.41 cm? (4 marks)
(ii) What is the probability that a component will have a thickness between
0.38 cm and 0.41 cm? (4 marks)
(iii) What is the thickness below which 25\% of the components will be? (4 marks)
\subsection{Example 3}
A charity believes that when it puts out an appeal for charitable donations the
donations it receives will normally distributed with a mean £50 and standard
deviation £6, and it is assumed that donations will be independent of each
other.
\begin{itemize}
	\item Find the probability that the first donation it receives will be greater
	than £40.
	\item Find the probability that it will be between £55 and £60.
	\item Find the value x such that 5\% of donations are more than £x.
\end{itemize}


%------------------------------------------------------------------------------------------------%