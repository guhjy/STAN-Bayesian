\documentclass[IntroMain.tex]{subfiles} 
\begin{document}
	
	\section{Basic Definitions of probability}
	%---------------------------------------------------------------------------------%
	\begin{frame}
		\frametitle{Probability}
		\Large
		\begin{itemize}
			\item The symbol P is used to designate the probability of an event. Thus P(A) denotes the probability that event
			A will occur in a single observation or experiment.
			
			\item The smallest value that a probability statement can have is 0 (indicating the event is impossible) and the
			largest value it can have is 1 (indicating the event is certain to occur). 
			\item Thus, in general:
			$0 	\leq P(A) \leq 1$
		\end{itemize}
	\end{frame}
	
	%---------------------------------------------------------------------------------%
	\begin{frame} 
		\frametitle{Mutually exclusive events}
		\Large
		\begin{itemize}
			\item In a given observation or experiment, an event must either occur or not occur. \item Therefore, the sum of the
			probability of occurrence plus the probability of nonoccurrence always equals 1. \item Thus, where $A^{\prime}$ indicates the nonoccurrence of event A, we have
			$P(A) + P(A^{c}) =  1$
		\end{itemize}
	\end{frame}
	%---------------------------------------------------------------------------------%
	\begin{frame} 
		\frametitle{Mutually exclusive events}
		\Large
		\begin{itemize}
			\item 
			Two or more events are mutually exclusive, or disjoint, if they cannot occur together. That is, the occurrence
			of one event automatically precludes the occurrence of the other event (or events). 
			\item For instance, suppose we
			consider the two possible events ``ace" and ``king" with respect to a card being drawn from a deck of playing
			cards. 
			\item These two events are mutually exclusive, because any given card cannot be both an ace and a king.
			\item Two or more events are nonexclusive when it is possible for them to occur together.
		\end{itemize} 
	\end{frame}
	%---------------------------------------------------------------------------------%
	\begin{frame} 
		\Large
		\begin{itemize}
			\item Note that this definition does not indicate that such events must necessarily always occur jointly. For instance, suppose we consider the two possible events ``ace" and ``spade". 
			\item These events are not mutually exclusive, because a given card can be both an ace and a spade; however, it does not follow that every ace is a spade or every spade is an ace.
		\end{itemize}
	\end{frame}
	%---------------------------------------------------------------------------------%
	\begin{frame}
		\frametitle{General rule of addition}
		\begin{itemize}
			\item For events that are not mutually exclusive, the probability of the joint occurrence of the two events is
			subtracted from the sum of the simple probabilities of the two events. We can represent the probability of joint
			occurrence by P(A and B).\item  In the language of set theory this is called the intersection of A and B and the
			probability is designated by P(A and B).  Thus, the rule of addition for events that are not mutually exclusive is
			\[ P(A \mbox{ or }B) = P(A)+ P(B) - P(A \mbox{ and }B)\]
		\end{itemize}
	\end{frame}
	%---------------------------------------------------------------------------------%
	\begin{frame} 
		\frametitle{Example}
		\Large
		When drawing a card from a deck of playing cards, the events ``ace" and ``spade" are not mutually
		exclusive. The probability of drawing an ace (A) or spade (S) (or both) in a single draw is
		\begin{eqnarray} P(A \mbox{ or }B) &=& P(A) + P(S) - P(A \mbox{ and }B)\\ &=& 4/52 + 13/52 -1/52 \\&=& 16/52 \\
		&=& \textbf{4/13} 
		\end{eqnarray}
	\end{frame}
	%---------------------------------------------------------------------------------%
	\section*{Independent events}
	\begin{frame}
		\Large
		\begin{itemize}
			\item Two events are independent when the occurrence or nonoccurrence of one event has no effect on the
			probability of occurrence of the other event. 
			
			\item Two events are dependent when the occurrence or nonoccurrence
			of one event does affect the probability of occurrence of the other event.
		\end{itemize}
		
	\end{frame}
	%---------------------------------------------------------------------------------%
	
	
	\section*{Conceptual approaches}
	\begin{frame}
		\Large
		\begin{itemize}
			\item Historically, three different conceptual approaches have been developed for defining probability and for
			determining probability values: the classical, relative frequency, and subjective approaches.\item If N(A) possible elementary outcomes are favorable to event A,
			N(S) possible outcomes are included in the sample space, and all the elementary outcomes are equally likely and
			mutually exclusive, then the probability that event A will occur is
			\[P(A) = \frac{N(A)}{N(S)}\]
		\end{itemize}
	\end{frame}
	\begin{frame} \frametitle{Examples}
		\Large
		When a fair dice is thrown, what are the possible outcomes? There are 6 possible outcomes. 
		
		The dice can role any number between one and six. Each outcome is equally likely. The probability of each outcome is 1/6.
	\end{frame}
	%---------------------------------------------------------------------------------%
	\begin{frame} 
		
		\Large
		In a well-shuffled deck of cards which contains 4 aces and 48 other cards, the probability of an ace (A)
		being obtained on a single draw is;
		\[ P(A)= N(A)/ N(S) = 4/52 = 1/13 \]
	\end{frame}
	%---------------------------------------------------------------------------------%
	\begin{frame} 
		
		\frametitle{Bayes theorem}
		\Large
		In its simplest algebraic form, Bayes theorem is concerned with determining the conditional probability of
		event A given that event B has occurred. 
		
		The general form of Bayes theorem is
		\[ P(A|B) =
		\frac{P(A \mbox{ and }B)}{P(B)} \]
	\end{frame}
	%---------------------------------------------------------------------------------%
	%---------------------------------------------------------------%
	\begin{frame}
		\frametitle{Probability Rules}
		\begin{itemize}
			
			\item The probability of an event which cannot occur is 0.
			
			\item The probability of any event which is not in the sample space is zero.
			
			\item The probability of an event which must occur is 1.
			
			\item The probability of the sample space is 1.
		\end{itemize}
	\end{frame}
	%---------------------------------------------------------------%
	\begin{frame}
		\frametitle{Probability Rules}
		\textbf{The Complement Rule}
		\begin{itemize}
			\item 
			The probability of an event not occurring is one minus the probability of it occurring.
			
			\[P(E^{C}) = 1 - P(E)\]
		\end{itemize}
	\end{frame}
	%---------------------------------------------------------------%
	%---------------------------------------------------------------%
	\begin{frame}
		\frametitle{Probability: Addition Rule for Any Two Events}
		\Large
		\vspace{-0.3cm}
		\begin{itemize}
			\item For any two events A and B, the probability of A or B is the sum of the probability of A and the probability of B minus the probability of both A and B:
			\[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]
			\vspace{-0.2cm}
			\item We subtract the probability of $A \cap B$ to prevent it getting counted twice.
			\large
			\item \textit{($A \cup B$ and $A \cap B$ denotes  ``A or B" and ``A and B" respectively) }
			
		\end{itemize}
	\end{frame}
	%---------------------------------------------------------------%
	%---------------------------------------------------------------%
	\begin{frame}
		\frametitle{Probability: Addition Rule for Any Two Events}
		\Large
		\begin{itemize}
			\item If events A and B are \textbf{mutually exclusive}, then the probability of A or B is the sum of the probability of A and the probability of B:
			
			\[P(A \cup B) = P(A) + P(B)\]
			
			\item If A and B are mutually exclusive, then the probability of both A and B is zero.
		\end{itemize}
	\end{frame}


%=========================================================%
\begin{frame}
	\frametitle{Introduction to Probability}
	\Large
	\textbf{Combining Probabilities}
	
	Events rarely occur in isolation. Usually we are interested in a combination or compound of events; for example
	\begin{itemize}
		\item The probability that two sections of a factory will be understaffed on the same day 
		\item The probability of having a car accident today, given that you have had a car accident in the last five years.
	\end{itemize}	
	
	We will look at two laws of probability for combining events
	\begin{itemize}
		\item The Addition Law 
		\item The multiplication Law
	\end{itemize}	
	
\end{frame}
%=========================================================%
\begin{frame}
	\frametitle{Introduction to Probability}
	\Large
	\textbf{Conditional Probability}
	The conditional probability of an event is the probability that an event A occurs given that another event B has already occurred. This type of probability is calculated by restricting the sample space that we’re working with to only the set B.
	
	The formula for conditional probability can be rewritten using some basic algebra. Instead of the formula:
	
	\[P(A | B) = \frac{P(A \cap B) }{P( B )}  \]
	
\end{frame}
%=========================================================%
\begin{frame}
	\frametitle{Introduction to Probability}
	\Large
	\textbf{Probability trees}
	The setting out of solutions to problems requiring the manipulation of the probabilities of mutually exclusive and independent events can sometimes be helped by the use of probability tree diagrams. These have useful applications in decision theory.
	
	The best choice of probability tree structure often depends upon the question and the natural order in which events like A and B above occur.
	
\end{frame}
%=========================================================%
\begin{frame}
	\frametitle{Introduction to Probability}
	\Large
	\textbf{Histograms}
	A histogram is constructed from a frequency table. The intervals are shown on the X-axis and the number of scores in each interval is represented by the height of a rectangle located above the interval. A histogram of the response times from the dataset Target RT is shown below.
	
\end{frame}
%=========================================================%
\begin{frame}
	\frametitle{Introduction to Probability}
	\Large
	
	\textbf{Cumulative Distribution Function}
	
	The cumulative distribution function (c.d.f.) of a discrete random variable X is the function F(t) which tells you the probability that X is less than or equal to t. So if X has p.d.f. P(X = x), we have:
	
	\[F(t) = P(X \leq 1)\] % = SP(X = x).
	
	In other words, for each value that X can be which is less than or equal to t, work out the probability that X is that value and add up all such results.
	
\end{frame}
%=========================================================%
\begin{frame}
	\frametitle{Introduction to Probability}
	\Large
	
	\textbf{Example}\\
	
	In the above example where the die is thrown repeatedly, lets work out $P(X \leq t)$ for some values of t.
	
	P(X $\leq$ 1) is the probability that the number of throws until we get a 6 is less than or equal to 1. So it is either 0 or 1. 
	
	\begin{itemize}
		\item P(X = 0) = 0 
		\item $P(X = 1) = 1/6$.
		\item  Hence $P(X \leq 1) = 1/6$
	\end{itemize}
	
	Similarly, $P(X \leq 2) = P(X = 0) + P(X = 1) + P(X = 2)$\\ = 0 + 1/6 + 5/36 = 11/36
	
\end{frame}
%================================================================================%
%--------------------------------------------------------------------------------%
\frame{
\frametitle{Conditional Probability}
Suppose $B$ is an event in a sample space $S$ with $P(B) > 0$.
The probability that an event $A$ occurs once $B$has occurred or, specifically, the
conditional probability of A given $B$ (written $P(A|B)$), is defined as follows:
\[ P(A|B) = \frac{P(A\cap B)}{P(B)}\]

\begin{itemize}
\item This can be expressed as a multiplication theorem
\[ P(A\cap B) = P(A|B)\times P(B) \]
\item The symbol $|$ is a vertical line and does not imply division.
\item Also $P(A|B)$ is not the same as $P(B|A)$.
\end{itemize}
Remark: The Prosecutor's Fallacy , with reference to the O.J. Simpson trial.
}

%--------------------------------------------------------------------------------%
\frame{
\frametitle{Independent Events}
Events A and B in a probability space $S$ are said to be independent if the
occurrence of one of them does not influence the occurrence of the other.\\ \bigskip

More specifically, $B$ is independent of A if $P(B)$ is the same as $P(B|A)$. Now
substituting $P(B)$ for $P(B|A)$ in the multiplication theorem from the previous
slide yields.
\[ P(A\cap B) = P(A)\times P(B)\]
We formally use the above equation as our definition of independence.

}
%--------------------------------------------------------------------------------%
\frame{
\frametitle{Mutually Exclusive Events}
\begin{itemize}
\item Two events are mutually exclusive (or disjoint) if it is impossible for
them to occur together.
\item Formally, two events $A$ and $B$ are mutually exclusive if and only if
$A\cap B$ = $\varnothing$ \end{itemize}\bigskip
Consider our die example
\begin{itemize} 
\item Event A = `observe an odd number' = $\{1,3,5\}$
\item Event B = `observe an even number' = $\{2,4,6\}$

\item $A\cap B$ = $\varnothing$ (i.e. the empty set), so $A$ and $B$ are mutually exclusive.
\end{itemize}
}

%--------------------------------------------------------------------------------%
\frame{
\frametitle{Addition Rule}
The addition rule is a result used to determine the probability that event $A$ or
event $B$ occurs or both occur. The result is often written as follows, using set
notation:
\[ P(A\cup B) = P(A) + P(B)- P(A \cap B)\] 
\begin{itemize}
\item $P(A)$ = probability that event $A$ occurs.
\item $P(B)$ = probability that event $B$ occurs.
\item $P(A\cup B)$ = probability that either event $A$ or event $B$ occurs, or both
occur.
\item $P(A\cap B)$ = probability that event $A$ and event $B$ both occur.
\end{itemize}\bigskip

\noindent \textbf{Remark:} $P(A\cap B)$ is subtracted to prevent the relevant outcomes being
counted twice.


}

%--------------------------------------------------------------------------------%
\frame{
\frametitle{Addition Rule (Continued)}
For mutually exclusive events, that is events which cannot occur together:
$P(A\cap B) = 0$. The addition rule therefore reduces to
\[ P(A\cup B) = P(A) + P(B)\]
}
%--------------------------------------------------------------------------------%
\frame{
\frametitle{Addition Rule: Worked Example}
Suppose we wish to find the probability of drawing either a Queen or a Heart
in a single draw from a pack of 52 playing cards. We define the events $Q$ =
`draw a queen' and $H$ = `draw a heart'.
\begin{itemize}
\item $P(Q)$ probability that a random selected card is a Queen
\item  $P(H)$ probability that a randomly selected card is a Heart.
\item  $P(Q\cap H)$ probability that a randomly selected card is the Queen of
Hearts.
\item  $P(Q\cup H)$ probability that a randomly selected card is a Queen or a Heart.
\end{itemize}
}
%--------------------------------------------------------------------------------%
\frame{
\frametitle{Solution}
\begin{itemize} 
\item Since there are 4 Queens in the pack and 13 Hearts, so the $P(Q)$ = $4/52$
and $P(H) = 13/52$ respectively.
\item The probability of selecting the Queen of Hearts is $P(Q\cap H) = 1/52$.
\item We use the addition rule to find $P(Q\cup H)$:
\[ P(Q\cup H) = (4/52) + (13/52) - (1/52) = 16/52 \]
\item So, the probability of drawing either a queen or a heart is
$16/52 (= 4/13)$.
\end{itemize}
}
%--------------------------------------------------------------------------------%

%-------------------------------------------------------%
\frame{
	\frametitle{Multiplication Rule}
	The multiplication rule is a result used to determine the probability that two events, $A$ and $B$, both occur.
	The multiplication rule follows from the definition of conditional probability.\\ \bigskip
	
	The result is often written as follows, using set notation:
	\[ P(A|B)\times P(B) = P(B|A)\times P(A) \qquad \left( = P(A \cap B) \right) \]
	
	Recall that for independent events, that is events which have no influence on one another, the rule simplifies to:
	\[P(A \cap B)  = P(A)\times P(B) \]
}
%-------------------------------------------------------%
\frame{
	\frametitle{Multiplication Rule}
	From the first year intake example, check that
	\[ P(E|F)\times P(F) = P(F|E)\times P(E)\]
	\begin{itemize}
		\item $P(E|F)\times P(F) = 0.58 \times 0.38  = 0.22$
		\item $P(F|E)\times P(E) = 0.55 \times 0.40  = 0.22$
	\end{itemize}
}
%------------------------------------------------------------%
\frame{
	\frametitle{Law of Total Probability}
	The law of total probability is a fundamental rule relating marginal probabilities to conditional probabilities. The result is often written as follows, using set notation:
	\[ P(A)  = P(A \cap B) + P(A \cap B^c) \]
	
	where $P(A \cap B^c)$ is probability that event $A$ occurs and $B$ does not.\\ \bigskip
	
	
	Using the multiplication rule, this can be expressed as
	\[ P(A) = P(A | B)\times P(B) + P(A | B^{c})\times P(B^{c}) \]
}
%------------------------------------------------------------%
\frame{
	\frametitle{Law of Total Probability}
	From the first year intake example , check that
	\[ P(E)  = P(E \cap M) + P(E \cap F) \]
	with $ P(E) = 0.40$, $ P(E \cap M) = 0.18$ and  $ P(E \cap F) = 0.22$
	\[ 0.40  = 0.18 + 0.22 \]
	\textbf{Remark:}  $M$ and $F$ are complement events.
	
}

%------------------------------------------------------------%
\frame{
	\frametitle{Bayes' Theorem}
	Bayes' Theorem is a result that allows new information to be used to update the conditional probability of an event.
	\bigskip
	
	Recall the definition of conditional probability:
	\[ P(A|B) = \frac{P(A \cap B)}{P(B)} \]
	
	
	Using the multiplication rule, gives Bayes' Theorem in its simplest form:
	
	\[ P(A|B) = \frac{P(B|A)\times P(A)}{P(B)} \]
	
}

%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example }
	An electronics assembly subcontractor receives resistors from two suppliers: Deltatech provides
	70\% of the subcontractors's resistors while another company, Echelon, supplies the remainder.
	\\
	1\% of the resistors provided by Deltatech fail the quality control test, while 2\% of the
	resistors from Echelon also fail the quality control test.
	
	\begin{enumerate}
		\item What is the probability that a resistor will fail the quality control test?
		\item What is the probability that a resistor that fails the quality control test was supplied by Echelon?
	\end{enumerate}
}

%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example}
	Firstly, let's assign names to each event.
	\begin{itemize}
		\item $D$ : a randomly chosen resistor comes from Deltatech.
		\item $E$ : a randomly chosen resistor comes from Echelon.
		\item $F$ : a randomly chosen resistor fails the quality control test.
		\item $P$ : a randomly chosen resistor passes the quality control test.
	\end{itemize}
	\bigskip
	We are given (or can deduce) the following probabilities:
	\begin{itemize}
		\item $P(D) = 0.70$,
		\item $P(E) = 0.30$.
	\end{itemize}
	
}
%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example}
	
	We are given two more important pieces of information:
	\begin{itemize}
		\item The probability that a randomly chosen resistor fails the quality control test, given that it comes from Deltatech: $P(F|D) = 0.01 $.
		\item The probability that a randomly chosen resistor fails the quality control test, given that it comes from Echelon: $P(F|E) = 0.02$.
	\end{itemize}
	
}
%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example}
	
	The first question asks us to compute the probability that a randomly chosen resistor fails the quality control test. i.e. $P(F)$.\\
	\bigskip
	All resistors come from either Deltatech or Echelon. So, using the \textbf{\emph{law of total probability}}, we can express $P(F)$ as follows:
	
	\[ P(F)  = P(F \cap D) + P(F \cap E) \]
	
}

%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example}
	
	Using the \textbf{\emph{multiplication rule}}  i.e. $P(A \cap B) = P(A|B) \times P(B)$, we can re-express the formula as follows
	
	\[ P(F)  = P(F|D) \times P(D) + P(F|E) \times P(E) \]
	
	We have all the necessary probabilities to solve this.
	
	\[ P(F)  = 0.01 \times 0.70 + 0.02 \times 0.30   = 0.007 + 0.006  = 0.013\]
	
}

%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example}
	
	\begin{itemize}
		\item
		The second question asks us to compute probability that a resistor that fails the quality control test was supplied by Echelon.
		\item In other words; of the resistors that did fail the quality test only, what is the probability that a randomly selected resistor was supplied by Echelon?
		\item We can express this mathematically as $P(E|F)$.
		\item We can use \textbf{\emph{Bayes' theorem}} to compute the answer.
	\end{itemize}
	
	
}
%------------------------------------------------------------%

\frame{
	\frametitle{Probability: Worked Example}
	Recall Bayes' theorem
	\[ P(A|B) = \frac{P(B|A)\times P(A)}{P(B)} \]
	\bigskip
	
	\[ P(E|F) = \frac{P(F|E)\times P(E)}{P(F)}  =  \frac{0.02 \times 0.30}{0.013} = 0.46\]
	
}
\frame{
\frametitle{More on probability}
For this lecture and the next.
\begin{enumerate}
\item Contingency Tables
\item Conditional Probability: Worked Examples
\item Joint Probability Tables
\item The Multiplication Rule
\item Law of Total Probability
\item Bayes' Theorem
\item Exam standard Probability Question
\item Random Variables
\end{enumerate}

}

\end{document}